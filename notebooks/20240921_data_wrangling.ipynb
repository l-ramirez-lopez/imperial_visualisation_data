{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfSnRyFM5yaN"
      },
      "source": [
        "<h1 class=\"title toc-ignore\" style=\"text-align:center;\"><strong>\n",
        "Group assignment: Data analysis and communication\n",
        "</strong></h1>\n",
        "\n",
        "<h3 class=\"subtitle\" style=\"text-align:center;\">\n",
        "    Data Analytics and Visualisation for Businessg<br>\n",
        "    Imperial College Business School\n",
        "</h3>\n",
        "\n",
        "<h4 class=\"author\" style=\"text-align:center;\">\n",
        "Nicolas Forster (CID _______); Kasra Khani (CID 02370755); Flaviano Moreira (CID 02288876); Leonardo Ramirez-Lopez (CID 02537657); Mark Shahbazi (CID ______)\n",
        "</h4>\n",
        "\n",
        "<h4 class=\"date\" style=\"text-align:center;\">September 09, 2024</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIy3HN9E81Ui"
      },
      "source": [
        "# __Load the datasets__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "QNSV1nNU1Wx8"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import requests as rq\n",
        "import json\n",
        "from datetime import date\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import ast\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "#from quantile_forest import RandomForestQuantileRegressor  # Adjusted import\n",
        "import pyproj\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "2j61p7pD85LD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# this is the url where all the files used in this study live\n",
        "loc = \"https://raw.githubusercontent.com/l-ramirez-lopez/data_share/main/\"\n",
        "\n",
        "# the files with the data of the houses on sale\n",
        "csv_file_sales = \"240908_idealista_sales.csv\"\n",
        "\n",
        "# the files with the data of the houses to rent\n",
        "csv_file_rent = \"240908_idealista_rent.csv\"\n",
        "\n",
        "# read the csv files\n",
        "df_sales_ini = pd.read_csv(loc + csv_file_sales)\n",
        "df_rent_ini = pd.read_csv(loc + csv_file_rent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQKRNVvp_hHL",
        "outputId": "f3fcba00-b04c-4a09-b8f9-e73b435f97b9"
      },
      "outputs": [],
      "source": [
        "    \n",
        "# display the first few rows of each dataframe to confirm successful loading\n",
        "print(\"Sales data dimensions\")\n",
        "print(df_sales_ini.shape)\n",
        "print(\"\\nRent data dimensions\")\n",
        "print(df_rent_ini.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckvg_R6sJoOP"
      },
      "source": [
        "# __Data wrangling__\n",
        "\n",
        "## Adding the variable `subtype_property`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "VtNCCBs4B62f"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import pandas as pd\n",
        "\n",
        "def extract_subproperty_type(df):\n",
        "    \"\"\"\n",
        "    Extract the subtype of the property type from the 'detailedType' column and store it in a new column named 'subtype_property'.\n",
        "    This function handles missing or NaN values in the 'detailedType' column.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas.DataFrame\n",
        "        The DataFrame containing a 'detailedType' column, where each entry is a string representation of a dictionary.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pandas.DataFrame\n",
        "        The modified DataFrame with a new column 'subtype_property', containing the extracted property subtype or NaN for missing values.\n",
        "\n",
        "    Raises:\n",
        "    -------\n",
        "    ValueError:\n",
        "        If the 'detailedType' string cannot be converted to a dictionary.\n",
        "\n",
        "    KeyError:\n",
        "        If the 'typology' key is not found in the 'detailedType' dictionary and it is not a NaN value.\n",
        "\n",
        "    TypeError:\n",
        "        If the 'detailedType' value is not a dictionary and cannot be processed.\n",
        "    \"\"\"\n",
        "    for index, row in df.iterrows():\n",
        "        detailed_type = row['detailedType']\n",
        "\n",
        "        # Check for NaN or missing values and handle them\n",
        "        if pd.isna(detailed_type):\n",
        "            df.at[index, 'subtype_property'] = pd.NA\n",
        "            continue\n",
        "\n",
        "        # Convert string representation of a dictionary to an actual dictionary\n",
        "        if isinstance(detailed_type, str):\n",
        "            try:\n",
        "                detailed_type = ast.literal_eval(detailed_type)\n",
        "            except (ValueError, SyntaxError):\n",
        "                raise ValueError(f\"Could not convert 'detailedType' to a dictionary: {detailed_type}\")\n",
        "\n",
        "        # Ensure detailed_type is now a dictionary\n",
        "        if isinstance(detailed_type, dict):\n",
        "            typology = detailed_type.get('typology')\n",
        "            if not typology:\n",
        "                raise KeyError(f\"'typology' not found in detailedType: {detailed_type}\")\n",
        "            df.at[index, 'subtype_property'] = detailed_type.get('subTypology', typology)\n",
        "        else:\n",
        "            raise TypeError(f\"'detailedType' is not a dictionary and cannot be processed: {detailed_type}\")\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "_ihe5NR4JSu-"
      },
      "outputs": [],
      "source": [
        "# Get the new variable of property subtype and add it to the dataset\n",
        "#and store it in a new dataframe\n",
        "df_sales = extract_subproperty_type(df_sales_ini)\n",
        "df_rent = extract_subproperty_type(df_rent_ini)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fxing the price of one of the properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "toO5rernLF82",
        "outputId": "d73b1736-7eae-4228-8fa5-8f9592e97072"
      },
      "outputs": [],
      "source": [
        "# After a manual inspection of houses with pirceByArea above 10000\n",
        "# we realised tha there was an error on the price of the property\n",
        "# with code 104562267. We checked at:\n",
        "# https://www.idealista.com/en/inmueble/104562267/\n",
        "# and fixed the price information as well as the priceByArea data\n",
        "# Update the 'price' for the specified propertyCode\n",
        "df_sales.loc[df_sales['propertyCode'] == 104562267, 'price'] = 380000\n",
        "\n",
        "# Recalculate 'priceByArea' as price divided by size\n",
        "df_sales.loc[df_sales['propertyCode'] == 104562267, 'priceByArea'] = df_sales['price'] / df_sales['size']\n",
        "\n",
        "# Display the updated row to verify\n",
        "df_sales[df_sales['propertyCode'] == 104562267]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exterior variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sales['propertyType'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the `exterior` variable, the missing values for properties of type 'flat', 'duplex', or 'studio' were assumed to be `False` as may property owners may tent to avoid providing details on this if their property do not face the exterior. For properties of type 'penthouse', 'chalet' or 'countryHouse' with missing values in the `exterior` variable, we assigng them a value of `True` as these properties typically face open spaces. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For 'flat', 'duplex', or 'studio' types, assume False for missing 'exterior'\n",
        "df_sales.loc[df_sales['propertyType'].isin(['flat', 'duplex', 'studio']) & df_sales['exterior'].isnull(), 'exterior'] = False\n",
        "df_rent.loc[df_rent['propertyType'].isin(['flat', 'duplex', 'studio']) & df_rent['exterior'].isnull(), 'exterior'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For 'penthouse', 'chalet', or 'countryHouse' types, assume True for missing 'exterior'\n",
        "df_sales.loc[df_sales['propertyType'].isin(['penthouse', 'chalet', 'countryHouse']) & df_sales['exterior'].isnull(), 'exterior'] = True\n",
        "df_rent.loc[df_rent['propertyType'].isin(['penthouse', 'chalet', 'countryHouse']) & df_rent['exterior'].isnull(), 'exterior'] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sales['exterior'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_rent['exterior'].isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Lift variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "sqLQOQxKOPf8"
      },
      "outputs": [],
      "source": [
        "# here we directly assume that if \"hasLift\" is missing is because it is False\n",
        "# Normally if the lift is not mentioned is because the house does not have one\n",
        "# as this is a key attribute for sales\n",
        "df_sales['hasLift'] = df_sales['hasLift'].fillna(False)\n",
        "df_rent['hasLift'] = df_rent['hasLift'].fillna(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adding easting and northing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "aexQSescinVf"
      },
      "outputs": [],
      "source": [
        "# Define the WGS 84 and UTM Zone 30N coordinate systems\n",
        "wgs84 = pyproj.CRS(\"EPSG:4326\")\n",
        "utm30n = pyproj.CRS(\"EPSG:25830\")\n",
        "\n",
        "# Create a transformer object\n",
        "transformer = pyproj.Transformer.from_crs(wgs84, utm30n, always_xy=True)\n",
        "\n",
        "# Function to transform coordinates\n",
        "def transform_coordinates(row):\n",
        "    easting, northing = transformer.transform(row['longitude'], row['latitude'])\n",
        "    return pd.Series({'easting': easting, 'northing': northing})\n",
        "\n",
        "# Apply the transformation to each row\n",
        "df_rent[['easting', 'northing']] = df_rent.apply(transform_coordinates, axis=1)\n",
        "df_sales[['easting', 'northing']] = df_sales.apply(transform_coordinates, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reviewing for variables with considerable amount of missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J4C4YZJx8AEd",
        "outputId": "7ad3c3a1-534f-4033-8af8-4e36caef2990"
      },
      "outputs": [],
      "source": [
        "# show the variables with that have some NAs for the sales dataset\n",
        "sales_nas = df_sales.isna().sum()\n",
        "sales_nas[sales_nas != 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dW1NVfnS0rAD",
        "outputId": "97c3444d-4714-455a-d543-e394e26244af"
      },
      "outputs": [],
      "source": [
        "# show the variables that have some NAs for the rent dataset\n",
        "rent_nas = df_rent.isna().sum()\n",
        "rent_nas[rent_nas != 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Floor variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "W28oxK8HvXPG"
      },
      "outputs": [],
      "source": [
        "# replacing the bj = bajos with 0 (Ground floor) and en = entresuelo with 10.5 (between ground and first floor)\n",
        "df_rent['floor'].replace(['en'], 0.5, inplace = True)\n",
        "df_rent['floor'].replace(['bj'], 0, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj7e5yN0JY5y",
        "outputId": "7a0f6b4d-d08a-4587-8d46-ec153651ec2a"
      },
      "outputs": [],
      "source": [
        "result = df_rent[df_rent['floor'].isna()]['propertyType'].value_counts()\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_rent['floor'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For imputing missing values in the `floor` variable, we calculated the median floor location for different property types ('penthouse', 'flat', 'studio', 'duplex'). We then used these mean values to impute the missing floor data for properties of the same type. For instance, missing floor values for penthouses were replaced with the median floor of all penthouses. This approach ensures consistency in the data and helps to prevent the loss of information due to missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XUsTkVUvEQ5",
        "outputId": "27813b27-b509-4ec0-d74a-5964fe73a5f7"
      },
      "outputs": [],
      "source": [
        "df_rent['floor'] = pd.to_numeric(df_rent['floor'], errors='coerce')\n",
        "median_floor_r_ph = df_rent.loc[df_rent['propertyType'] == 'penthouse', 'floor'].median()\n",
        "median_floor_r_f = df_rent.loc[df_rent['propertyType'] == 'flat', 'floor'].median()\n",
        "median_floor_r_st = df_rent.loc[df_rent['propertyType'] == 'studio', 'floor'].median()\n",
        "median_floor_r_dx = df_rent.loc[df_rent['propertyType'] == 'duplex', 'floor'].median()\n",
        "print(\"penthouse =\", median_floor_r_ph, \"flat =\", median_floor_r_f, \"studio =\", median_floor_r_st, \"duplex =\", median_floor_r_dx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "flkJpPLQHl09"
      },
      "outputs": [],
      "source": [
        "# Replace NaN values in df_rent.floor based on df_rent.propertyType\n",
        "df_rent.loc[(df_rent.floor.isna()) & (df_rent.propertyType == 'penthouse'), 'floor'] = median_floor_r_ph\n",
        "df_rent.loc[(df_rent.floor.isna()) & (df_rent.propertyType == 'flat'), 'floor'] = median_floor_r_f\n",
        "df_rent.loc[(df_rent.floor.isna()) & (df_rent.propertyType == 'studio'), 'floor'] = median_floor_r_st\n",
        "df_rent.loc[(df_rent.floor.isna()) & (df_rent.propertyType == 'duplex'), 'floor'] = median_floor_r_dx\n",
        "df_rent.loc[(df_rent.floor.isna()) & (df_rent.propertyType == 'chalet'), 'floor'] = 0\n",
        "df_rent.loc[(df_rent.floor.isna()) & (df_rent.propertyType == 'countryHouse'), 'floor'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j90FnLAmMsW_",
        "outputId": "b24c0a62-4cc5-48d7-bbad-9f19408a717a"
      },
      "outputs": [],
      "source": [
        "df_rent['floor'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "HUqEl86zNnry",
        "outputId": "79779990-8b49-4104-fdc6-9c8364bcacd4"
      },
      "outputs": [],
      "source": [
        "df_rent.floor.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhobEacOM9_L",
        "outputId": "9fd73249-a1ca-489d-f3fc-df9727a63aec"
      },
      "outputs": [],
      "source": [
        "df_sales.floor.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "3Oq4pnnNQm6l",
        "outputId": "dbfaca5b-8fbb-49d8-ab02-cfc52f1c0e6b"
      },
      "outputs": [],
      "source": [
        "df_sales.floor.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "98lJ0IJglSE2"
      },
      "outputs": [],
      "source": [
        "# replacing the bj = bajos with 0 (Ground floor) and en = entresuelo with 0.5 (between ground and first floor), ss and st as -1 for \"subsuelo\"\n",
        "df_sales['floor'].replace(['en'], 0.5, inplace=True)\n",
        "df_sales['floor'].replace(['bj'], 0, inplace=True)\n",
        "df_sales['floor'].replace(['ss'], -1, inplace=True)\n",
        "df_sales['floor'].replace(['st'], -1, inplace=True) #we need to check what st"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "4FvhgLZylUsw",
        "outputId": "66736189-7253-4f5d-a0ea-3af0cc5889ff"
      },
      "outputs": [],
      "source": [
        "df_sales.floor.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEFPMS6yMt_4",
        "outputId": "0ed59c79-9eb7-4d58-ef27-01c62f1ec0b4"
      },
      "outputs": [],
      "source": [
        "df_sales['floor'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XRmaYwXIB-S",
        "outputId": "71c3bb83-5268-4ffb-9a9b-b52acf5f7940"
      },
      "outputs": [],
      "source": [
        "df_sales['floor'] = pd.to_numeric(df_sales['floor'], errors='coerce')\n",
        "median_floor_s_ph = df_sales.loc[df_sales['propertyType'] == 'penthouse', 'floor'].median()\n",
        "median_floor_s_f = df_sales.loc[df_sales['propertyType'] == 'flat', 'floor'].median()\n",
        "median_floor_s_dx = df_sales.loc[df_sales['propertyType'] == 'duplex', 'floor'].median()\n",
        "median_floor_s_st = df_sales.loc[df_sales['propertyType'] == 'studio', 'floor'].median()\n",
        "\n",
        "print(\"flat = \", median_floor_s_f, \"penthouse = \", median_floor_s_ph, \"duplex = \", median_floor_s_dx, \"studio = \", median_floor_s_st)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "XJIzl74gG7mF"
      },
      "outputs": [],
      "source": [
        "# Replace NaN values in 'floor' based on 'propertyType'\n",
        "df_sales.loc[(df_sales.floor.isna()) & (df_sales.propertyType == 'flat'), 'floor'] = median_floor_s_f\n",
        "df_sales.loc[(df_sales.floor.isna()) & (df_sales.propertyType == 'penthouse'), 'floor'] = median_floor_s_ph\n",
        "df_sales.loc[(df_sales.floor.isna()) & (df_sales.propertyType == 'duplex'), 'floor'] = median_floor_s_dx\n",
        "df_sales.loc[(df_sales.floor.isna()) & (df_sales.propertyType == 'studio'), 'floor'] = median_floor_s_st\n",
        "df_sales.loc[(df_sales.floor.isna()) & (df_sales.propertyType == 'chalet'), 'floor'] = 0\n",
        "df_sales.loc[(df_sales.floor.isna()) & (df_sales.propertyType == 'countryHouse'), 'floor'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBfGt19L7GPi",
        "outputId": "08337b1d-91bf-4fe8-9b0f-ae9150fc9a4b"
      },
      "outputs": [],
      "source": [
        "df_sales['floor'].isna().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "7xjXyZKMNqkn",
        "outputId": "26da851d-7973-44bb-8312-dd3d2fd40e70"
      },
      "outputs": [],
      "source": [
        "df_sales.floor.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variables 'formerPrice', 'priceDropValue', 'priceDropPercentage'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "HyBilp6RnU8L"
      },
      "outputs": [],
      "source": [
        "def extract_price_drop_info(row):\n",
        "  \"\"\"\n",
        "  Extracts price drop information from the 'priceInfo' column and creates new columns.\n",
        "\n",
        "  Args:\n",
        "    row: A row from the DataFrame.\n",
        "\n",
        "  Returns:\n",
        "    A pandas Series containing the extracted price drop information.\n",
        "  \"\"\"\n",
        "  price_info = row['priceInfo']\n",
        "  if pd.isna(price_info):\n",
        "    return pd.Series([pd.NA, pd.NA, pd.NA], index=['formerPrice', 'priceDropValue', 'priceDropPercentage'])\n",
        "\n",
        "  if isinstance(price_info, str):\n",
        "    try:\n",
        "      price_info = ast.literal_eval(price_info)\n",
        "    except (ValueError, SyntaxError):\n",
        "      return pd.Series([pd.NA, pd.NA, pd.NA], index=['formerPrice', 'priceDropValue', 'priceDropPercentage'])\n",
        "\n",
        "  if isinstance(price_info, dict):\n",
        "    price_dict = price_info.get('price')\n",
        "    if price_dict and isinstance(price_dict, dict):\n",
        "      price_drop_info = price_dict.get('priceDropInfo')\n",
        "      if price_drop_info and isinstance(price_drop_info, dict):\n",
        "        former_price = price_drop_info.get('formerPrice')\n",
        "        price_drop_value = price_drop_info.get('priceDropValue')\n",
        "        price_drop_percentage = price_drop_info.get('priceDropPercentage')\n",
        "        return pd.Series([former_price, price_drop_value, price_drop_percentage], index=['formerPrice', 'priceDropValue', 'priceDropPercentage'])\n",
        "  return pd.Series([pd.NA, pd.NA, pd.NA], index=['formerPrice', 'priceDropValue', 'priceDropPercentage'])\n",
        "\n",
        "\n",
        "# Apply the function to create new columns\n",
        "df_rent[['formerPrice', 'priceDropValue', 'priceDropPercentage']] = df_rent.apply(extract_price_drop_info, axis=1)\n",
        "df_sales[['formerPrice', 'priceDropValue', 'priceDropPercentage']] = df_sales.apply(extract_price_drop_info, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Updpate properties 101746143 and 32797738"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "WlVJj71fx0-U"
      },
      "outputs": [],
      "source": [
        "# update status = 2 for the propertyCode = 101746143 in df_sales 101746143 is a new development in Alicante and 32797738 is a property in good conditions\n",
        "df_sales.loc[df_sales['propertyCode'] == 101746143, 'status'] = 2\n",
        "df_sales.loc[df_sales['propertyCode'] == 32797738, 'status'] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "BHPyCK-nyhIy"
      },
      "outputs": [],
      "source": [
        "# update the df_sales['status'] to 0 is 'renew', 1 if 'good' and 2 if 'newdevelopment'\n",
        "df_sales['status'] = df_sales['status'].replace({'renew': 0, 'good': 1, 'newdevelopment': 2})\n",
        "df_rent['status'] = df_rent['status'].replace({'renew': 0, 'good': 1, 'newdevelopment': 2})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parking variable \n",
        "\n",
        "For imputing missing values for the `parking` variable, we assumed that property owners who did not indicate whether the property has parking likely do not have one. Therefore, all missing values were replaced with `False`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sales['parking'] = df_sales['parkingSpace'].apply(lambda x: x.get('hasParkingSpace') if isinstance(x, dict) else None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "def extract_has_parking_space(parking_string):\n",
        "    try:\n",
        "        parking_dict = ast.literal_eval(parking_string)  # Convert the string to a dictionary\n",
        "        return parking_dict.get('hasParkingSpace')  # Extract the 'hasParkingSpace' value\n",
        "    except (ValueError, SyntaxError):\n",
        "        return None  # Return None if conversion or extraction fails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sales['parking'] = df_sales['parkingSpace'].apply(extract_has_parking_space)\n",
        "df_rent['parking'] = df_rent['parkingSpace'].apply(extract_has_parking_space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_sales.loc[df_sales['parking'].isna(), 'parking'] = False\n",
        "df_rent.loc[df_rent['parking'].isna(), 'parking'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find duplicated properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNx_zfZme9r3",
        "outputId": "33a0aadd-8b0c-4e2f-c957-52f95415ad75"
      },
      "outputs": [],
      "source": [
        "# find duplicates in df_rent\n",
        "# (returns only the second and subsequent occurrences of the duplicates)\n",
        "duplicate_rows_rent = df_rent[df_rent.duplicated()]\n",
        "print(\"Duplicate Rows in df_rent:\")\n",
        "print(duplicate_rows_rent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm2r9dmgfnb6",
        "outputId": "8341590a-cf2b-42ac-fe78-ef52c2a2ed58"
      },
      "outputs": [],
      "source": [
        "# find duplicates in df_sales\n",
        "duplicate_rows_sales = df_sales[df_sales.duplicated()]\n",
        "print(\"Duplicate Rows in df_sales:\")\n",
        "print(duplicate_rows_sales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILSWyhT6fz0o",
        "outputId": "64da7c4e-94c0-4d1b-bec4-914f462aa096"
      },
      "outputs": [],
      "source": [
        "# number of duplicates in df_sales\n",
        "num_duplicates_sales = df_sales.duplicated().sum()\n",
        "print(f\"There are {num_duplicates_sales} duplicate rows in df_sales.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "KOhTr4BhgBzc"
      },
      "outputs": [],
      "source": [
        "# eliminate duplicates in df_rent and df_sales\n",
        "df_rent = df_rent.drop_duplicates()\n",
        "df_sales = df_sales.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Utm-pUXwgSjR",
        "outputId": "4694e8e4-33b4-45a7-f6cd-95d1f763321c"
      },
      "outputs": [],
      "source": [
        "print(f\"New number of rows in df_rent: {len(df_rent)}\")\n",
        "print(f\"New number of rows in df_sales: {len(df_sales)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H60Bu40hCHD",
        "outputId": "91d7d167-6496-41b8-bcb5-758114c7abe1"
      },
      "outputs": [],
      "source": [
        "# find the rows in df_rent the rows where the data in 55 colums has the same value but not in the columns propertyCode, thumbnail, latitude, longitude, url,description, externalReference\n",
        "\n",
        "# Select columns to check for duplicates, excluding specified columns\n",
        "cols_to_check = [col for col in df_rent.columns if col not in ['propertyCode', 'thumbnail', 'latitude', 'longitude', 'url', 'description', 'externalReference']]\n",
        "\n",
        "# Find rows where the specified columns have the same values\n",
        "duplicate_rows = df_rent[df_rent.duplicated(subset=cols_to_check, keep=False)]\n",
        "\n",
        "# Print the duplicate rows\n",
        "print(duplicate_rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# find the rows in df_rent the rows where the data in 55 colums has the same value but not in the columns propertyCode, thumbnail, latitude, longitude, url,description, externalReference\n",
        "\n",
        "# Select columns to check for duplicates, excluding specified columns\n",
        "cols_to_check = [col for col in df_rent.columns if col in ['description', 'bathrooms', 'rooms']]\n",
        "\n",
        "# Find rows where the specified columns have the same values\n",
        "duplicate_rows = df_rent[df_rent.duplicated(subset = cols_to_check, keep = False)]\n",
        "\n",
        "# Print the duplicate rows\n",
        "duplicate_rows.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Status variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a mapping for the replacements\n",
        "status_mapping = {0: \"renew\", 1: \"good\", 2: \"newdevelopment\"}\n",
        "\n",
        "# Replace the values in the 'status' column using .loc\n",
        "df_sales.loc[:, 'status'] = df_sales['status'].replace(status_mapping)\n",
        "\n",
        "# Display the updated column\n",
        "print(df_sales['status'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_rent[df_rent['status'] == 0]['propertyCode']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Duplicated properties\n",
        "\n",
        "Some properties had identical textual descriptions, with the same number of bathrooms and rooms, although other fields differed. This suggests that some duplicate properties remain in the dataset. However, they were not removed, as it was unclear which of the differing fields contained the most accurate information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select columns to check for duplicates, excluding specified columns\n",
        "cols_to_check = [col for col in df_sales.columns if col in ['description', 'bathrooms', 'rooms']]\n",
        "\n",
        "# Find rows where the specified columns have the same values\n",
        "duplicate_rows = df_sales[df_sales.duplicated(subset = cols_to_check, keep = False)]\n",
        "duplicate_rows.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End of data wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XCvbwEZv8Vj"
      },
      "source": [
        "At this point we assume the data is cleaned and prepared to conduct modelling analyses. We then proceed to save this data in csv files:\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
